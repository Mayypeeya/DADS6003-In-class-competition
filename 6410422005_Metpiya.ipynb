{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Metpiya Lertakkakorn 6410422005","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-06-04T15:28:48.532867Z","iopub.execute_input":"2022-06-04T15:28:48.533158Z","iopub.status.idle":"2022-06-04T15:28:48.541536Z","shell.execute_reply.started":"2022-06-04T15:28:48.533128Z","shell.execute_reply":"2022-06-04T15:28:48.540671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import Libraries ที่สำคัญ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt \nfrom scipy.stats import zscore\nfrom scipy import stats\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.neural_network import MLPClassifier","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:40:42.540012Z","iopub.execute_input":"2022-06-12T15:40:42.540354Z","iopub.status.idle":"2022-06-12T15:40:43.770517Z","shell.execute_reply.started":"2022-06-12T15:40:42.540264Z","shell.execute_reply":"2022-06-12T15:40:43.769627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"สร้าง dataframe เพื่อรับข้อมูล train & test set เพื่อใช้ในการสร้างตัวแบบ","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/dads6003-in-class-competition/train.csv')\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:41:01.941477Z","iopub.execute_input":"2022-06-12T15:41:01.942145Z","iopub.status.idle":"2022-06-12T15:41:02.045983Z","shell.execute_reply.started":"2022-06-12T15:41:01.942112Z","shell.execute_reply":"2022-06-12T15:41:02.045183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/dads6003-in-class-competition/test.csv')\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:41:03.931737Z","iopub.execute_input":"2022-06-12T15:41:03.932013Z","iopub.status.idle":"2022-06-12T15:41:03.978161Z","shell.execute_reply.started":"2022-06-12T15:41:03.931977Z","shell.execute_reply":"2022-06-12T15:41:03.977266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape, df_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:41:07.041734Z","iopub.execute_input":"2022-06-12T15:41:07.042011Z","iopub.status.idle":"2022-06-12T15:41:07.048799Z","shell.execute_reply.started":"2022-06-12T15:41:07.04198Z","shell.execute_reply":"2022-06-12T15:41:07.047891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Cleansing data","metadata":{}},{"cell_type":"markdown","source":"แบ่งข้อมูล train set ออกเป็น feature & label เพื่อจัดการข้อมูลก่อนนำไปสร้างตัวแบบ","metadata":{}},{"cell_type":"code","source":"x_train = df_train.loc[:, 'x1':'x20']\nx_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:41:09.597854Z","iopub.execute_input":"2022-06-12T15:41:09.598167Z","iopub.status.idle":"2022-06-12T15:41:09.627637Z","shell.execute_reply.started":"2022-06-12T15:41:09.598138Z","shell.execute_reply":"2022-06-12T15:41:09.626745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = df_train.y\ny_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:41:11.670245Z","iopub.execute_input":"2022-06-12T15:41:11.670669Z","iopub.status.idle":"2022-06-12T15:41:11.676857Z","shell.execute_reply.started":"2022-06-12T15:41:11.670638Z","shell.execute_reply":"2022-06-12T15:41:11.676037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:41:14.041354Z","iopub.execute_input":"2022-06-12T15:41:14.041682Z","iopub.status.idle":"2022-06-12T15:41:14.047385Z","shell.execute_reply.started":"2022-06-12T15:41:14.041651Z","shell.execute_reply":"2022-06-12T15:41:14.046762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:41:15.622705Z","iopub.execute_input":"2022-06-12T15:41:15.623498Z","iopub.status.idle":"2022-06-12T15:41:15.643909Z","shell.execute_reply.started":"2022-06-12T15:41:15.623461Z","shell.execute_reply":"2022-06-12T15:41:15.643327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:41:18.32835Z","iopub.execute_input":"2022-06-12T15:41:18.3289Z","iopub.status.idle":"2022-06-12T15:41:18.336473Z","shell.execute_reply.started":"2022-06-12T15:41:18.328864Z","shell.execute_reply":"2022-06-12T15:41:18.335595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"พบว่ายังมีหลาย column ที่ยังมีค่าช่องว่าง คือมีไม่ครบ 7,500 rows จากข้อมูล features ทั้งหมด<br>\nจึงสร้างกราฟ histogram เพื่อดูการแจกแจงของข้อมูลแต่ละ features ก่อนจะเลือกวิธีการจัดการกับข้อมูลที่เป็นช่องว่าง","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(5, 4,figsize=(20, 20))\nsns.histplot(ax=axes[0,0], x=x_train.x1)\nsns.histplot(ax=axes[0,1], x=x_train.x2)\nsns.histplot(ax=axes[0,2], x=x_train.x3)\nsns.histplot(ax=axes[0,3], x=x_train.x4)\nsns.histplot(ax=axes[1,0], x=x_train.x5)\nsns.histplot(ax=axes[1,1], x=x_train.x6)\nsns.histplot(ax=axes[1,2], x=x_train.x7)\nsns.histplot(ax=axes[1,3], x=x_train.x8)\nsns.histplot(ax=axes[2,0], x=x_train.x9)\nsns.histplot(ax=axes[2,1], x=x_train.x10)\nsns.histplot(ax=axes[2,2], x=x_train.x11)\nsns.histplot(ax=axes[2,3], x=x_train.x12)\nsns.histplot(ax=axes[3,0], x=x_train.x13)\nsns.histplot(ax=axes[3,1], x=x_train.x14)\nsns.histplot(ax=axes[3,2], x=x_train.x15)\nsns.histplot(ax=axes[3,3], x=x_train.x16)\nsns.histplot(ax=axes[4,0], x=x_train.x17)\nsns.histplot(ax=axes[4,1], x=x_train.x18)\nsns.histplot(ax=axes[4,2], x=x_train.x19)\nsns.histplot(ax=axes[4,3], x=x_train.x20)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:41:22.430571Z","iopub.execute_input":"2022-06-12T15:41:22.430963Z","iopub.status.idle":"2022-06-12T15:41:28.023139Z","shell.execute_reply.started":"2022-06-12T15:41:22.430934Z","shell.execute_reply":"2022-06-12T15:41:28.022229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"จากกราฟด้านบนพบว่าแทบทุก feature มีการแจกแจกปกติ ยกเว้น X2 ที่มีการเบ้เล็กน้อย และ X9 ที่มีความหนาแน่นตรงค่า 0 สูงขึ้นมา จึงเลือกใช้ค่า median ในการจัดการกับข้อมูล N/A","metadata":{}},{"cell_type":"code","source":"x_train_fillna = x_train.fillna(x_train.median())\nx_train_fillna.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:41:52.144422Z","iopub.execute_input":"2022-06-12T15:41:52.144704Z","iopub.status.idle":"2022-06-12T15:41:52.164556Z","shell.execute_reply.started":"2022-06-12T15:41:52.144675Z","shell.execute_reply":"2022-06-12T15:41:52.163664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"เนื่องจาก scale ของแต่ละ feature ยังมีขนาดต่างกันมากอยู่ ดูได้จากค่า mean, median, min หรือ maxของแต่ละ features ที่มีค่าต่างกันมาก และเนื่องจากข้อมมูลส่วนใหญ่มีการแจกแจงแบบปกติจึงจะปรับ scale ของข้อมูลด้วยวิธี z score normalization เพื่อให้ข้อมูลในทุก feature มีขนาดเดียวกัน","metadata":{}},{"cell_type":"code","source":"x_train_norm = zscore(x_train_fillna)\nx_train_norm.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:41:57.56603Z","iopub.execute_input":"2022-06-12T15:41:57.566899Z","iopub.status.idle":"2022-06-12T15:41:57.637186Z","shell.execute_reply.started":"2022-06-12T15:41:57.566857Z","shell.execute_reply":"2022-06-12T15:41:57.636589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Exploratory Data Analysis (describe insight and visualization)","metadata":{}},{"cell_type":"markdown","source":"จำนวน classification (y) ของจำนวนข้อมูล train set","metadata":{}},{"cell_type":"code","source":"sns.countplot( x='y' , data=df_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:42:01.591536Z","iopub.execute_input":"2022-06-12T15:42:01.59201Z","iopub.status.idle":"2022-06-12T15:42:01.711973Z","shell.execute_reply.started":"2022-06-12T15:42:01.591977Z","shell.execute_reply":"2022-06-12T15:42:01.710953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ตรวจสอบการแจกแจงของข้อมูลเปรียบเทียบการเปลี่ยนแปลงอีกครั้งระหว่าง ข้อมูลเริ่มต้น, ข้อมูลเมื่อจัดการช่องว่างด้วย median และข้อมูลเมื่อทำการ normalization","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(20, 3,figsize=(20, 40))\n# raw data\nsns.histplot(ax=axes[0,0], x=x_train.x1)\naxes[0,0].set_title('raw data frame')\naxes[0,0].set_ylabel('X1')\n# fill na data\nsns.histplot(ax=axes[0,1], x=x_train_fillna.x1)\naxes[0,1].set_title('fill na with median')\naxes[0,1].set_ylabel('X1')\n# normalization data\nsns.histplot(ax=axes[0,2], x=x_train_norm.x1)\naxes[0,2].set_title('z-score normalization')\naxes[0,2].set_ylabel('X1')\n\nsns.histplot(ax=axes[1,0], x=x_train.x2)\naxes[1,0].set_ylabel('X2')\nsns.histplot(ax=axes[1,1], x=x_train_fillna.x2)\naxes[1,1].set_ylabel('X2')\nsns.histplot(ax=axes[1,2], x=x_train_norm.x2)\naxes[1,2].set_ylabel('X2')\n\nsns.histplot(ax=axes[2,0], x=x_train.x3)\naxes[2,0].set_ylabel('X3')\nsns.histplot(ax=axes[2,1], x=x_train_fillna.x3)\naxes[2,1].set_ylabel('X3')\nsns.histplot(ax=axes[2,2], x=x_train_norm.x3)\naxes[2,2].set_ylabel('X3')\n\nsns.histplot(ax=axes[3,0], x=x_train.x4)\naxes[3,0].set_ylabel('X4')\nsns.histplot(ax=axes[3,1], x=x_train_fillna.x4)\naxes[3,1].set_ylabel('X4')\nsns.histplot(ax=axes[3,2], x=x_train_norm.x4)\naxes[3,2].set_ylabel('X4')\n\nsns.histplot(ax=axes[4,0], x=x_train.x5)\naxes[4,0].set_ylabel('X5')\nsns.histplot(ax=axes[4,1], x=x_train_fillna.x5)\naxes[4,1].set_ylabel('X5')\nsns.histplot(ax=axes[4,2], x=x_train_norm.x5)\naxes[4,2].set_ylabel('X5')\n\nsns.histplot(ax=axes[5,0], x=x_train.x6)\naxes[5,0].set_ylabel('X6')\nsns.histplot(ax=axes[5,1], x=x_train_fillna.x6)\naxes[5,1].set_ylabel('X6')\nsns.histplot(ax=axes[5,2], x=x_train_norm.x6)\naxes[5,2].set_ylabel('X6')\n\nsns.histplot(ax=axes[6,0], x=x_train.x7)\naxes[6,0].set_ylabel('X7')\nsns.histplot(ax=axes[6,1], x=x_train_fillna.x7)\naxes[6,1].set_ylabel('X7')\nsns.histplot(ax=axes[6,2], x=x_train_norm.x7)\naxes[6,2].set_ylabel('X7')\n\nsns.histplot(ax=axes[7,0], x=x_train.x8)\naxes[7,0].set_ylabel('X8')\nsns.histplot(ax=axes[7,1], x=x_train_fillna.x8)\naxes[7,1].set_ylabel('X8')\nsns.histplot(ax=axes[7,2], x=x_train_norm.x8)\naxes[7,2].set_ylabel('X8')\n\nsns.histplot(ax=axes[8,0], x=x_train.x9)\naxes[8,0].set_ylabel('X9')\nsns.histplot(ax=axes[8,1], x=x_train_fillna.x9)\naxes[8,1].set_ylabel('X9')\nsns.histplot(ax=axes[8,2], x=x_train_norm.x9)\naxes[8,2].set_ylabel('X9')\n\nsns.histplot(ax=axes[9,0], x=x_train.x10)\naxes[9,0].set_ylabel('X10')\nsns.histplot(ax=axes[9,1], x=x_train_fillna.x10)\naxes[9,1].set_ylabel('X10')\nsns.histplot(ax=axes[9,2], x=x_train_norm.x10)\naxes[9,2].set_ylabel('X10')\n\nsns.histplot(ax=axes[10,0], x=x_train.x11)\naxes[10,0].set_ylabel('X11')\nsns.histplot(ax=axes[10,1], x=x_train_fillna.x11)\naxes[10,1].set_ylabel('X11')\nsns.histplot(ax=axes[10,2], x=x_train_norm.x11)\naxes[10,2].set_ylabel('X11')\n\nsns.histplot(ax=axes[11,0], x=x_train.x12)\naxes[11,0].set_ylabel('X12')\nsns.histplot(ax=axes[11,1], x=x_train_fillna.x12)\naxes[11,1].set_ylabel('X12')\nsns.histplot(ax=axes[11,2], x=x_train_norm.x12)\naxes[11,2].set_ylabel('X12')\n\nsns.histplot(ax=axes[12,0], x=x_train.x13)\naxes[12,0].set_ylabel('X13')\nsns.histplot(ax=axes[12,1], x=x_train_fillna.x13)\naxes[12,1].set_ylabel('X13')\nsns.histplot(ax=axes[12,2], x=x_train_norm.x13)\naxes[12,2].set_ylabel('X13')\n\nsns.histplot(ax=axes[13,0], x=x_train.x14)\naxes[13,0].set_ylabel('X14')\nsns.histplot(ax=axes[13,1], x=x_train_fillna.x14)\naxes[13,1].set_ylabel('X14')\nsns.histplot(ax=axes[13,2], x=x_train_norm.x14)\naxes[13,2].set_ylabel('X14')\n\nsns.histplot(ax=axes[14,0], x=x_train.x15)\naxes[14,0].set_ylabel('X15')\nsns.histplot(ax=axes[14,1], x=x_train_fillna.x15)\naxes[14,1].set_ylabel('X15')\nsns.histplot(ax=axes[14,2], x=x_train_norm.x15)\naxes[14,2].set_ylabel('X15')\n\nsns.histplot(ax=axes[15,0], x=x_train.x16)\naxes[15,0].set_ylabel('X16')\nsns.histplot(ax=axes[15,1], x=x_train_fillna.x16)\naxes[15,1].set_ylabel('X16')\nsns.histplot(ax=axes[15,2], x=x_train_norm.x16)\naxes[15,2].set_ylabel('X16')\n\nsns.histplot(ax=axes[16,0], x=x_train.x17)\naxes[16,0].set_ylabel('X17')\nsns.histplot(ax=axes[16,1], x=x_train_fillna.x17)\naxes[16,1].set_ylabel('X17')\nsns.histplot(ax=axes[16,2], x=x_train_norm.x17)\naxes[16,2].set_ylabel('X17')\n\nsns.histplot(ax=axes[17,0], x=x_train.x18)\naxes[17,0].set_ylabel('X18')\nsns.histplot(ax=axes[17,1], x=x_train_fillna.x18)\naxes[17,1].set_ylabel('X18')\nsns.histplot(ax=axes[17,2], x=x_train_norm.x18)\naxes[17,2].set_ylabel('X18')\n\nsns.histplot(ax=axes[18,0], x=x_train.x19)\naxes[18,0].set_ylabel('X19')\nsns.histplot(ax=axes[18,1], x=x_train_fillna.x19)\naxes[18,1].set_ylabel('X19')\nsns.histplot(ax=axes[18,2], x=x_train_norm.x19)\naxes[18,2].set_ylabel('X19')\n\nsns.histplot(ax=axes[19,0], x=x_train.x20)\naxes[19,0].set_ylabel('X20')\nsns.histplot(ax=axes[19,1], x=x_train_fillna.x20)\naxes[19,1].set_ylabel('X20')\nsns.histplot(ax=axes[19,2], x=x_train_norm.x20)\naxes[19,2].set_ylabel('X20')","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:42:17.895342Z","iopub.execute_input":"2022-06-12T15:42:17.895888Z","iopub.status.idle":"2022-06-12T15:42:33.729835Z","shell.execute_reply.started":"2022-06-12T15:42:17.895829Z","shell.execute_reply":"2022-06-12T15:42:33.729148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"พบว่าการแจกแจงของข้อมูลทุก feature หลังจากการจัดการข้อมูลที่ผ่านมายังคงสภาพเดิม และขนาด scale ของทุก feature มีค่าที่ช่วงเดียวกันแล้ว<br>\nจากนั้นจะใช้กราฟ correlation เพื่อดูความสัมพันธ์ของ feature แต่ละตัวเปรียบเทียบกันระหว่าง ข้อมูลเริ่มต้น, ข้อมูลเมื่อจัดการช่องว่างด้วย median และข้อมูลเมื่อทำการ normalization เพื่อจะรักษาคุณสมบัติของ feature ให้ตามเดิม","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 3,figsize=(20, 5))\nsns.heatmap(df_train.corr(), cmap=\"PiYG\", ax=axes[0])\naxes[0].set_title('raw data')\nsns.heatmap(x_train_fillna.corr(), cmap=\"PiYG\", ax=axes[1])\naxes[1].set_title('fill na with median')\nsns.heatmap(x_train_norm.corr(), cmap=\"PiYG\", ax=axes[2])\naxes[2].set_title('z-score normalization')","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:42:48.456896Z","iopub.execute_input":"2022-06-12T15:42:48.457703Z","iopub.status.idle":"2022-06-12T15:42:50.028923Z","shell.execute_reply.started":"2022-06-12T15:42:48.457661Z","shell.execute_reply":"2022-06-12T15:42:50.028093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Training data - Crossvalidation","metadata":{}},{"cell_type":"markdown","source":"นำข้อมูลมา train ด้วย MLPClassifier โดยใช้ Optimiser Algorithm คือ Adaptive Moment Estimation (adam) <br>\ntrain โดยการใช้ Crossvalidation: k-fold = 5 เพื่อดูค่าประสิทธิภาพของผลลัพธ์ที่ได้ทุกชุดของการ train และความแปรปรวนของประสิทธิภาพโมเดล","metadata":{}},{"cell_type":"code","source":"clf = MLPClassifier(random_state=0, max_iter=2000, activation = 'logistic', alpha = 0.05\n                   ,beta_1 = 0.9, beta_2 = 0.9999, epsilon = 1e-9, n_iter_no_change = 10)\nKFold = KFold(n_splits=5, shuffle=False)\nkfold = KFold.split(x_train_norm, y_train)\nscores = []\n\nfor k, (train, test) in enumerate(kfold):\n    clf.fit(x_train_norm.iloc[train, :], y_train.iloc[train])\n    score = clf.score(x_train_norm.iloc[test, :], y_train.iloc[test])\n    scores.append(score)\n    print('Fold: %2d, Training/Test Split Distribution: %s, Accuracy: %.3f' % (k+1, np.bincount(y_train.iloc[train]), score))\n \nprint('\\n\\nCross-Validation accuracy: %.3f +/- %.3f' %(np.mean(scores), np.std(scores)))","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:14:21.647623Z","iopub.execute_input":"2022-06-12T08:14:21.647938Z","iopub.status.idle":"2022-06-12T08:17:15.262784Z","shell.execute_reply.started":"2022-06-12T08:14:21.647904Z","shell.execute_reply":"2022-06-12T08:17:15.261886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"score ของ model มีค่าเฉลี่ยของ 5 รอบคือ 0.983 และมีความแปรปรวนคือ 0.003<br>\nจากนั้นลองตรวจสอบอีกครั้งโดยใช้ model ที่ได้มาทำนาย และดูประสิทธิภาพกับข้อมูล train set ทั้งหมด 7,500 instance","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\n\ntest = confusion_matrix(y_train, clf.predict(x_train_norm))\nprint(test)\nprint(test.shape) \ntn, fp, fn, tp = confusion_matrix(y_train, clf.predict(x_train_norm)).ravel()\nprint(\"tp=\",tp,\" fp=\",fp)\nprint(\"fn=\",fn,\" tn=\", tn)\n\nprecision = metrics.precision_score(y_train, clf.predict(x_train_norm))\nrecall = metrics.recall_score(y_train, clf.predict(x_train_norm))\nf1 = metrics.f1_score(y_train, clf.predict(x_train_norm))\nf1_weighted = metrics.f1_score(y_train, clf.predict(x_train_norm), average = 'weighted')\naccuracy = metrics.accuracy_score(y_train, clf.predict(x_train_norm))\n\nprint(\"accuracy = \", accuracy)\nprint(\"precision = \",precision)\nprint(\"recall = \", recall)\nprint(\"f1 = \", f1)\nprint(\"f1 weighted = \", f1_weighted)\nprint(metrics.classification_report(y_train, clf.predict(x_train_norm)))","metadata":{"execution":{"iopub.status.busy":"2022-06-12T15:47:37.939352Z","iopub.execute_input":"2022-06-12T15:47:37.940069Z","iopub.status.idle":"2022-06-12T15:47:38.298502Z","shell.execute_reply.started":"2022-06-12T15:47:37.940032Z","shell.execute_reply":"2022-06-12T15:47:38.295755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Testing data","metadata":{}},{"cell_type":"markdown","source":"เตรียมข้อมูล test set เพื่อนำ model ที่ได้ไปทำนาย classification ","metadata":{}},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:43:57.777276Z","iopub.execute_input":"2022-06-12T08:43:57.777606Z","iopub.status.idle":"2022-06-12T08:43:57.793923Z","shell.execute_reply.started":"2022-06-12T08:43:57.777533Z","shell.execute_reply":"2022-06-12T08:43:57.792469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:44:03.551418Z","iopub.execute_input":"2022-06-12T08:44:03.55237Z","iopub.status.idle":"2022-06-12T08:44:03.618946Z","shell.execute_reply.started":"2022-06-12T08:44:03.552201Z","shell.execute_reply":"2022-06-12T08:44:03.618038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = zscore(df_test)\ndf_test.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:44:06.581405Z","iopub.execute_input":"2022-06-12T08:44:06.58263Z","iopub.status.idle":"2022-06-12T08:44:06.650764Z","shell.execute_reply.started":"2022-06-12T08:44:06.582506Z","shell.execute_reply":"2022-06-12T08:44:06.649808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# output\npredict = clf.predict(df_test)\nfields = ['id','Expected']\ndf = pd.DataFrame()\nid = list(range(1,2501))\ndf['id']=pd.Series(id)\ndf['Expected']=pd.Series(predict)\ndf.to_csv('submit3.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T08:44:11.693713Z","iopub.execute_input":"2022-06-12T08:44:11.694441Z","iopub.status.idle":"2022-06-12T08:44:11.732595Z","shell.execute_reply.started":"2022-06-12T08:44:11.694244Z","shell.execute_reply":"2022-06-12T08:44:11.731482Z"},"trusted":true},"execution_count":null,"outputs":[]}]}